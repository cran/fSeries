\documentclass[a4paper,11pt]{article}
\usepackage{epsfig,graphicx,amssymb}
\usepackage{amsmath}
\usepackage{parskip}
\usepackage[bookmarks=true,bookmarksopen=true,bookmarksnumbered=true,linkbordercolor={1 1 1}]{hyperref}

\hypersetup{
    pdfauthor = {Diethelm Wuertz},
    pdftitle = {GARCH Modelling},
    pdfsubject = {finGARCH},
    pdfkeywords = {GARCH},
    pdfcreator = {LaTeX with hyperref package},
    pdfproducer = {dvips + ps2pdf}}

    \setlength{\topmargin}{-1.5cm}
    \setlength{\headheight}{1.5cm}
    \setlength{\headsep}{0.8cm}
    \setlength{\textheight}{23cm} %14/23
    \setlength{\oddsidemargin}{-0.0cm}
    \setlength{\evensidemargin}{-0.0cm}
    \setlength{\textwidth}{16cm}
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}
    %\linespread{0.9}

\begin{document}

\pdfbookmark[1]{finGARCH: Titlepage}{Titlepage}

\begin{titlepage}
\title{
   \vspace{0cm}
   Computing with R\\
   Teaching Computational Finance\\[1cm]
   \textbf{Modelling Univariate GARCH Processes\\
   \vspace{0.5cm}
   finGARCH -  User Guide}
   }
\author{
   Diethelm W\"urtz \\[12.5cm]
   Institut f\"ur Theoretische Physik \\
   ETH Z\"urich
   }

\end{titlepage}

\maketitle


% *****************************************************************************

\newpage

\section{Introduction}

\vspace{0.5cm}

\emph{In particular, [we] analyzes[d] seven widely used [GARCH]\\
 packages, utilizing a recently developed benchmark. Four of the\\
 packages are found to be unsuitable, in most cases because the\\
 developer either does not specifically indicate which of the many\\
 possible GARCH models is being estimated, or does not accommodate\\
 the most common model specified in the applied literature, or\\
 both. A principal finding is that implementation of the GARCH\\
 procedure varies so widely that two packages ostensibly doing the\\
 same thing actually may be estimating substantively different\\
 models.\\
 %\htmladdnormallink{ETH}{http://bollerslev86a.pdf}\\
 McCullough and Renfro 1999}


%\emph{Using the term nonlinear to describe a time \\
% series model is like saying that zoology is the \\
% study of nonelephant animals.\\
% \\
% S. Ulam, Nobel Price in Physics}

\vspace{1.5cm}

GARCH, \emph{Generalized Autoregressive Conditional
Heteroskedastic}, models have become important in the analysis of
time series data, particularly in financial applications when the
goal is to analyze and forecast volatility. For this purpose, we
describe a \textsc{R}-package for simulating, estimating and
forecasting various univariate GARCH-type time series models in
the conditional variance and an ARMA specification in the
conditional mean. We present a numerical implementatation of the
Maximum Likelihood approach under four assumptions, Normal,
Student-t, GED or skewed Student-t errors. The parameter estimates
are checked by several diagnostic analysis tools including
graphical features and hypothesis tests. One step ahead forecasts
of both the conditional mean and variance are available.

In this document we consider as a first step univariate ARMA,
models with GARCH, errors. The name GARCH is considered in a
broader sense denoting a whole family of models. The number of
GARCH models is immense, but the most influential models were the
first. Beside the standard ARCH model introduced by Engle (1982)
and the GARCH model introduced by Bollerslev (10986), we consider
also the more general class of asymmetric power ARCH models
(APARCH) introduced by Ding, Granger and Engle (1993). APARCH
models itself include as special cases the TS-GARCH model of
Taylor (1986) and Schwert (1989), the GJR-GARCH model of Glosten,
Jaganathan, and Runkle (1993), the T-ARCH model of Zakoian (1993),
the N-ARCH model of Higgins and Bera (1992), and the Log-ARCH
model of Geweke (1986) and Pentula (1986).

Coupled with these models was a sophisticated analysis of the
stochastic process of data generated by the underlying process as
well as estimators for the unknown model parameters. Theorems for
the autocorrelations, moments and stationarity and ergodicity of
GARCH processes have been developed for many of the important
cases. There exist a collection of review articles by Bollerslev,
Chou and Kroner(1992), Bera and Higgins(1993), Bollerslev, Engle
and Nelson(1994), Engle(2001), Engle and Patton(2001), Li, Ling
and McAleer(2002) that give a good overview of the scope of the
research.

The aim of this user guide is threefold. It gives a brief
introduction to the concepts of GARCH time series modelling, it
shows how the algorithms are implemented in the \textsf{R}
environment using the S language, and gives some useful hints and
suggestions for adding your own functions.

% home number is +493419135969 Mridual
% mobile number is +491625812275

% -----------------------------------------------------------------------------

\newpage
\section{Mean and Variance Equation}

\vspace{0.5cm}

We describe the mean equation of an univariate time series $y_t$
by the process

\begin{equation}
    y_t ~=~ E(y_t|\Omega_{t-1}) + \varepsilon_t ~,
\end{equation}

where $E(\cdot|\cdot)$ denotes the conditional expectation
operator, $\Omega_{t-1}$ the information set at tine $t-1$, and
$\varepsilon_t$ the innovations or residuals of the time series.
$\varepsilon_t$ describes uncorrelated disturbances with zero mean
and plays the role of the unpredictable part of the time series.
In the following we model the mean equation as an ARMA process,
and the innovations are generated from a GARCH process.


\subsection{ARMA Mean Equation}

The ARMA(m,n) process of autoregressive order $m$ and moving
average order $n$ can be described as

\vspace{-0.5cm}

\begin{eqnarray}\label{arma}
    y_t & = & \mu
        ~ + ~ \sum_{i=1}^m a_i y_{t-i}
        ~ + ~ \sum_{j=1}^n b_j \varepsilon_{t-j} ~, \nonumber
    \\
    & = & \mu
        ~ + ~ a(\mathcal{B}) y_t
        ~ + ~ b(\mathcal{B}) \varepsilon_t ~,
\end{eqnarray}

with mean $\mu$, autoregressive coefficients $a_i$ and moving
average coefficients $b_i$. Note, that the model can be expressed
in a quite comprehensive form using the backshift operator
$\mathcal{B}$ defined by $\mathcal{B}x_t=x_{t-1}$. The functions
$a(\mathcal{B})$ and $b(\mathcal{B})$ are polynomials of degree
$m$ and $n$ respectively in the backward shift operator
$\mathcal{B}$. If $m=0$ we have a pure autoregressive process and
if on the other hand $n=0$ we have a pure moving average process.

The ARMA time series is \emph{stationary} when the series
$a(\mathcal{B})$, which is the generating function of the
coefficients $a$, converges for $|\mathcal{B}| < 1$ that is, on or
within the unit circle.


\subsection{GARCH Variance Equation}

The mean equation cannot take into account for heteroskedastic
effects of the time series process typically observed in form of
fat tails, as clustering of volatilities, and the leverage effect.
In this context Engle (1982) introduced the \emph{Autoregressive
Conditional Heteroskedastic} model, named ARCH, later generalized
by Bollerslev (1986), named GARCH.

The $\varepsilon_t$ terms in the ARMA mean equation (\ref{arma})
are the innovations of the time series process. Engle (1982)
defined them as an autoregressive conditional heteroscedastic
process where all $\varepsilon_t$ are of the form

\vspace{-0.5cm}

\begin{equation}\label{engle}
    \varepsilon_t ~ = ~ z_t ~ \sigma_t ~,
\end{equation}

where $z_t$ is an \emph{iid} process with zero mean and unit
variance. Although $\varepsilon_t$ is serially uncorrelated by
definition its conditional variance equals $\sigma_t^2$ and,
therefore, may change over time. All the GARCH models we consider
in the following differ only in their functional form for the
conditional variance.

%\vspace{0.5cm}
\newpage

\textsf{The GARCH Model:}

The variance equation of the GARCH(p,q) model can be expressed as:

\vspace{-0.5cm}

\begin{eqnarray}
    \varepsilon_t & = & z_t \sigma_t ~,
        \nonumber
    \\
    z_t & \sim &
        \mathcal{D}(0,1) ~,
        \nonumber
    \\
    \sigma_t^2 & = & \omega
       ~+~ \sum_{i=1}^q \alpha_i \varepsilon_{t-i}^2
       ~+~ \sum_{j=1}^p \beta_j \sigma_{t-j}^2 ~, \nonumber
    \\
    & = & \omega
        ~+~ \alpha(\mathcal{B}) \varepsilon_{t-1}^2
        ~+~ \beta(\mathcal{B}) \sigma_{t-1}^2
\end{eqnarray}

where $\mathcal{D}(0,1)$ is the probability density function of
the innovations or residuals with zero mean and unit variance. If
all the coefficients $\beta$ are zero the GARCH model is reduced
to the ARCH model. Like for ARMA models a GARCH specification
often leads to a more parsimonious representation of the temporal
dependencies and thus provides a similar added flexibility over
the linear ARCH model when parameterizing the conditional
variance.

Bolerslev (1986) has shown that the GARCH(p,q) process is
wide-sense stationary with $E(\varepsilon_t)=0$,
$var(\varepsilon_t)=\omega/(1-\alpha(1)-\beta(1))$ and
$cov(\varepsilon_t,\varepsilon_s)=0$ for $t \neq s$ if and only if
$\alpha(1)+\beta(1)<1$.

\vspace{0.5cm}

\textsf{The APARCH Model:}

The variance equation of the APARCH(p,q) model can be written as:

\vspace{-0.5cm}

\begin{eqnarray}
    \varepsilon_t & = & z_t \sigma_t ~,
        \nonumber
    \\
    z_t & \sim &
        \mathcal{D}(0,1) ~,
        \nonumber
    \\
    \sigma_t^\delta & = & \omega
       ~+~ \sum_{i=1}^q \alpha_i
        ( | \varepsilon_{t-i} | - \gamma_i \varepsilon_{t-i} )^\delta
       ~+~ \sum_{j=1}^p \beta_j \sigma_{t-j}^\delta ~,
\end{eqnarray}

where $\delta > 0$ and $-1 < \gamma_i < 1$. This model has been
introduced by Ding, Granger, and Engle (1993). It adds the
flexibility of a varying exponent with an asymmetry coefficient to
take the leverage effect into account. A stationary solution
exists if $\omega > 0$, and $\Sigma_i \alpha_i \kappa_i + \Sigma_j
\beta_j < 1$, where $\kappa_i = E(|z|+\gamma_i z)^\delta$. Note,
that if $\gamma \neq 0$ and/or $\delta \neq 2$ the $\kappa_i$
depend on the assumptions made on the innovation process.

The APARCH includes seven other ARCH extensions as special cases:

\vspace{0.25cm}

%\footnotesize
\begin{quote}
\begin{itemize}
    \item \emph{ARCH Model of Engle}
        when $\delta=2$, $\gamma_i=0$, and $\beta_j=0$.
    \item \emph{GARCH Model of Bollerslev}
        when $\delta=2$, and $\gamma_i=0$.
    \item \emph{TS-GARCH Model of Taylor and Schwert}
        when $\delta=1$, and $\gamma_i=0$.
    \item \emph{GJR-GARCH Model of Glosten, Jagannathan, and Runkle}
        when $delta=2$.
    \item \emph{T-ARCH Model of Zakoian}
        when $delta=1$.
    \item \emph{N-ARCH Model of Higgens and Bera}
        when $\gamma_i=0$, and $\beta_j=0$.
    \item \emph{Log-ARCH Model of Geweke and Pentula}
        when $\delta \rightarrow 0$.
\end{itemize}
\end{quote}
%\normalsize


% -----------------------------------------------------------------------------


\newpage

\section{GARCH Modelling Process}

\vspace{0.5cm}

The modelling of a GARCH process consists of several steps: The
specification of the model, the generation of artificial time
series for simulation and testing, the parameter estimation, the
diagnostic analysis, and the computation of forecasts. For each
step a \textsf{R}-function is available.

\vspace{0.5cm}

\footnotesize
    \textbf{Functions for GARCH Modelling Process:}\\
    \begin{itemize}
        \item \texttt{garchSpec} - specifies the GARCH
            model. The function creates a GARCH specification
            object of class \texttt{"garchSpec"}.
        \item \texttt{garchSim} - simulates an artificial GARCH
            time series.
        \item \texttt{garchFit} - fits the parameters to the
            model. This function estimates the time series
            coefficients and the distributional parameters of a
            specified GARCH model.
        \item \texttt{print}, \texttt{plot}, \texttt{summary},
            - are methods for an object returned by the function
            \texttt{"garchFit"}. These functions print and plot
            results, create a summary report and perform a diagnostic
            analysis.
        \item \texttt{predict} - forecasts one step ahead from
            an estimated model. This function can be used to
            predict future volatility from a GARCH model.
    \end{itemize}
\normalsize


\vspace{0.5cm}

\subsection{Specification Structure}

The \textsf{R}-function \texttt{garchSpec} creates a S4 object
called \emph{specification structure} which specifies a GARCH
process. This function maintains information that defines a model
used for time series simulation, parameter estimation and
diagnostic analysis.

\vspace{0.5cm}

\footnotesize
 \textbf{Class Representation for the Specification Structure:}\\
  \vspace{-0.25cm}
  \begin{verbatim}
    setClass("garchSpec",
      representation(
        call = "call",
        formula = "formula",
        model = "list",
        distribution = "list",
        presample = "matrix",
        title = "character",
        description = "character"
      )
    )
 \end{verbatim}
\normalsize


The slots of the object include the string which matches the call
of the function, a formula expression that describes the model, a
list with the model parameters, a list with the distributional
specification of the innovations, and a presample matrix to
initiate the GARCH process. Additionally, a title and a short
description can be added to the specification structure.

The meaning of the arguments of the function \texttt{garchSpec}
together with the default values is summarized in the following
list:


%\vspace{0.5cm}
\newpage

\footnotesize
 \textbf{Function: GARCH Specification Function - }
 \texttt{garchSpec}\\
 \vspace{-0.25cm}
 \begin{verbatim}
    garchSpec =
        function (model = list(omega = 1e-6, alpha = 0.1, beta = 0.8),
        distribution = c("norm", "snorm", "ged", "sged", "std", "sstd"),
        presample = NA, title = NULL, description = NULL)
 \end{verbatim}
 \vspace{-0.25cm}
 \begin{itemize}
    \item \texttt{model} - a list with the model parameters as entries
        \begin{itemize}
            \item \texttt{ar} - a vector of autoregressive coefficients
                of length \texttt{m} for the ARMA specification,
            \item \texttt{ma} - a vector of moving average coefficients
                of length n for the ARMA specification,
            \item \texttt{omega} - the variance value for GARCH/APARCH
                specification,
            \item \texttt{alpha} - a vector of autoregressive coefficients
                of length \texttt{p} for the GARCH/APARCH specification,
            \item \texttt{gamma} - a vector of leverage coefficients
                of length \texttt{p} for the APARCH specification,
            \item \texttt{beta} - a vector of moving average coefficients
                of length \texttt{q} for the GARCH/APARCH specification,
            \item \texttt{mu} - the mean value for ARMA/GARCH specification,
            \item \texttt{delta} - the exponent value used in the
                variance equation,
            \item \texttt{parm} - a vector of two shape parameters
                measuring the degree of skewness and kurtosis.
        \end{itemize}
        By default a GARCH(1,1) process with $\omega = 10^{-6}$,
        $\alpha = 0.1$, and $\beta = 0.8$ with normal innovations
        will be created.
    \item \texttt{distribution} - a string selecting the desired
        distributional form of the innovations either \texttt{norm}
        for the Normal, \texttt{ged} for the Generalized Error,
        \texttt{std} for the Standardized Student-t, or \texttt{snorm},
        \texttt{sged}, \texttt{sstd}, for one of the skewed distributions.
        By default the normal distribution will be selected.
    \item \texttt{presample} - a numeric \texttt{"matrix"} with
        \texttt{3} columns and at least \texttt{max(m,n,p,q)}
        rows. The first column holds the \emph{pre-innovations}, the
        second the \emph{pre-sigmas}, and the third the \emph{pre-series}.
        Otherwise, if presample takes the value \texttt{NA}, which is the
        default, or is specified as a positive integer, then the
        presample will be automatically created of minimal or of the
        specified length.
    \item \texttt{title} - a character variable associated with a
        title. By default NULL, which means that the title will be
        automatically set.
    \item \texttt{description} - a character string associated with a
        description of the GARCH specification. By default NULL, which
        means that a brief description will be automatically set.
 \end{itemize}
\normalsize

\vspace{0.25cm}

The function \texttt{garchSpec} has a print method which produces
for the GARCH(1,1) default specification the following report:

\vspace{0.5cm}
 \footnotesize
 \textbf{Exercise: Print Method for GARCH Specification - }
 \texttt{xmpGarchSpecification}\\
 \vspace{-0.25cm}
 \begin{verbatim}
    > print(garchSpec())

    Call: garchSpec()

           Title:  ARMA - GARCH/APARCH Specification
         Formula:  ~garch(1, 1)
           Model:
           omega:  1e-06
           alpha:  0.1
            beta:  0.8
           delta:  2
    Distribution:  norm
       Parameter:  NA    1
       Presample:
                     time              z            h              y
                   1    0  -0.1422962187  1.000000e-05  0.000000e+00
     Description:
                   Specification as of Wed Jan 07 20:34:51 2004
 \end{verbatim}
\normalsize

In the following we describe in more detail the specification of
the formula and model object, the distribution object and the
presample object.


% *****************************************************************************


\vspace{0.5cm}


\textsf{The Formula and Model Specification:}


The \texttt{formula} object describes the GARCH model and is
automatically created from the \texttt{model} list, e.g. ARMA(m,n)
+ GARCH(p,q). ARMA can be missing or specified as AR(m) or MA(n)
in the case of pure autoregressive or moving average models.
GARCH(p,q) may be alternatively specified as ARCH(p) or
APARCH(p,q).


\vspace{0.5cm}


\textsf{The Distribution Specification:}


The \texttt{distribution} object selects one from six possible
probability functions. The default choice for the distribution of
the innovations $z_t$ to simulate or to estimate the parameters of
a GARCH process is the \emph{Standardized Normal Probability
Function}\footnote{The Normal probability function is selected by
setting \texttt{distribution="norm"}.}

\vspace{-0.2cm}

\begin{equation}\label{normal.distribution}
    f^\star(z) ~=~
        \frac{1}{\sqrt{2\pi}} ~ e^{-\frac{z^2}{2}} ~.
\end{equation}


The probability function or density is named standardized, marked
by a star ${}^\star$, because $f^\star(z)$ has zero mean and unit
variance. This can easily be verified computing the \emph{moments}

\vspace{-0.2cm}

\begin{equation}\label{raw.central.moments}
    \mu^\star_r  ~ = ~ \int_{-\infty}^\infty z^r f^\star(z) dz ~.
\end{equation}


Note, that $\mu^\star_0 \equiv 1$ is the normalization condition,
that $\mu^\star_1$ defines the mean $\mu \equiv 0$, and
$\mu^\star_2$ the variance $\sigma^2 \equiv 1$.

An arbitrary Normal distribution located around a mean value $\mu$
and scaled by the standard deviation $\sigma$ can be obtained by
introducing a \emph{location} and a \emph{scale} parameter through
the transformation

\vspace{-0.2cm}

\begin{equation}\label{transformation}
    f(z) dz
    ~ \rightarrow ~
        \frac{1}{\sigma} f^\star \Big( \frac{z-\mu}{\sigma} \Big) dz
    ~ = ~
        \frac{1}{\sigma\sqrt{2\pi}} ~ e^{-\frac{(z-\mu)^2}{2\sigma^2}} dz ~.
\end{equation}


The \emph{central moments} $\mu_r$ of $f(z)$ can simply be
expressed in terms of the moments $\mu^\star_r$ of the
standardized distribution $f^\star(z)$. Odd central moments are
zero and those of even order can be computed from


\begin{equation}\label{norm.moments}
    \mu_{2r}
        ~ = ~\int_{-\infty}^\infty (z-\mu)^{2r} f(z) dz
        ~ = ~ \sigma^{2r} \mu^\star_{2r} ~=~  \sigma^{2r} \,
            \frac{2^r}{\sqrt{\pi}} \,
                \Gamma \Big( r + \frac{1}{2} \Big) ~,
\end{equation}


yielding $\mu_2=0$, and $\mu_4=3$. The degree of asymmetry
$\gamma_1$ of a probability function, named \emph{skewness}, and
the degree of peakedness $\gamma_2$, named \emph{excess kurtosis},
can be measured by normalized forms of the third and fourth
central moments.


\begin{equation}\label{central.moments}
    \gamma_1 = \frac{\mu_3}{\mu_2^{3/2}} = 0 ~, ~~~~
    \gamma_2 = \frac{\mu_4}{\mu_2^2} - 3 = 0 ~.
\end{equation}


However, if we like to model an asymmetric and/or leptokurtic
shape of the innovations we have to draw or to model $z_t$ from a
standardized probability function which depends on additional
shape parameters which modify the skewness and kurtosis. However,
it is important that the probability has still zero mean and unit
variance. Otherwise, it would be impossible, or at least
difficult, to separate the fluctuations in the mean and variance
from the fluctuations in the shape of the density. In a first step
we consider still symmetric probability functions but with an
additional shape parameter which models the kurtosis. As examples
we consider the generalized error distribution and the Student-t
distribution with unit variance, both relevant in modelling GARCH
processes.


% -----------------------------------------------------------------------------


\vspace{0.5cm}


\emph{Generalized Error Distribution:}


Nelson [1991] suggested to consider the family of
\emph{Generalized Error Distributions}\footnote{The Generalized
error distribution is selected by setting
\texttt{distribution="ged"}.}, GED, already used by Box and Tiao
[1973]\footnote{Box and Tiao call the GED exponential power
distribution.} and Harvey [1981]. $f^\star(z|\nu)$ can be
expressed as

\begin{eqnarray}\label{ged.distribution}
    f^\star (z|\nu) & = &
    \frac{\nu}{\lambda_\nu 2^{1+1/\nu} \Gamma(1/\nu)} ~
    e ^ {-
        \frac{1}{2}|\frac{z}{\lambda_\nu}|^\nu
        }~,
    \\
    \lambda_\nu & = &
        \left (
            \frac
                { 2^{(-2/\nu)} \Gamma \big(\frac{1}{\nu} \big) }
                { \Gamma \big (\frac{3}{\nu} \big) }
        \right )^{1/2}
    \nonumber
\end{eqnarray}


with $0 < \nu \leq \infty$. Note, that the density is standardized
and thus has zero mean and unit variance. Arbitrary location and
scale parameters $\mu$ and $\sigma$ can be introduced via the
transformation $ z \rightarrow \frac{z-\mu}{\sigma}$. Since the
density is symmetric, odd central moments of the GED are zero and
those of even order can be computed from

\begin{equation}\label{ged.moments}
    \mu_{2r} ~=~ \sigma^{2r} \mu^\star_{2r} ~=~ \sigma^{2r} \,
            \frac
                { (2^{1/\nu} \lambda_\nu )^{2r} }
                { \Gamma \big( \frac{1}{\nu} \big) }
            \Gamma \Big( \frac{2r+1}{\nu} \Big) ~.
\end{equation}


Skewness $\gamma_1$ and kurtosis $\gamma_2$ are given by


\begin{equation}\label{ged.central.moments}
    \gamma_1 = \frac{\mu_3}{\mu_2^{3/2}} = 0 ~, ~~~~
    \gamma_2 = \frac{\mu_4}{\mu_2^2} - 3 =
        \frac
            {\Gamma\big(\frac{1}{\nu}\big)
                \Gamma\big(\frac{5}{\nu}\big)}
            {\Gamma\big(\frac{3}{\nu}\big)^2} - 3 ~.
\end{equation}


For $\nu=1$ the GED reduces to the Laplace distribution, for
$\nu=2$ to the Normal distribution, and for $\nu \rightarrow
\infty$ to the uniform distribution as a special case\footnote{The
Laplace Distribution takes the form $f(z) = \frac{1}{\sqrt{2}}
e^{-\sqrt{2}|z|}$, and the uniform distribution has range $\pm 2
\sqrt{3}$}.

%
%
%*********************************************************************
\begin{figure}
\hspace{1cm}
\includegraphics[width=14cm]{figures/Figure1.pdf}
%\caption
\footnotesize{
\\ $\blacksquare$
Figure 1: The figure shows on top the density and distribution for
the GED. Three cases are considered: The leptokurtic \emph{Laplace
Distribution} with $\nu=1$, the \emph{Normal Distribution} with
$\nu=2$, and the almost \emph{Uniform Distribution} for large
$\nu=10$. On the lower left the ratio of two succeeding absolute
moments is displayed. For the Laplace distribution we get a
straight line, for distributions with thinner tails than the
Laplace distribution, the curve bends upwards, and for
distributions with thicker tails the curve bends downwards. On the
lower right the 4th moment as a function of the shape parameter
$\nu$ is shown. Since the distribution is standardized, the fourth
moment coincides with the value of the kurtosis. Note, to obtain
the excess kurtosis we have to subtract $3$. For $\nu \rightarrow
0$ the kurtosis diverges and for $\nu \rightarrow \infty$ the
kurtosis tends to one. The circles mark the values for the Laplace
and Normal distributions. The code to produces these figures can
be found in the example file \texttt{xmpGarchDISTged}.}
\end{figure}
%*********************************************************************
%
%

\vspace{0.5cm}

\footnotesize
 \textbf{Function: GED Distribution - }
 \texttt{[dpqr]ged}
 \begin{quote}
      In this example we show how to write a function to compute
      density, distribution function, quantile function and how to
      generate random deviates for the generalized error distribution
      with mean equal to \texttt{mean}, standard deviation equal
      to \texttt{sd}, and shape parameter equal to \texttt{nu}.

      \emph{Hint:} To Compute the distribution function $F(x) =
      \int_{-\infty}^x f(z) dz$ transform $\frac{1}{2}
      |\frac{z}{\lambda_\nu}|^\nu \rightarrow z$ and make use of the
      relationship to the Gamma distribution function which is
      part of \textsf{R}'s base package.

      \vspace{0.25cm}

      \begin{verbatim}
      # Density Function:
        dged = function(x, mean = 0, sd = 1, nu = 2) {
          # x - Vector of quantiles
          x = (x - mean ) / sd
          lambda = sqrt ( 2^(-2/nu) * gamma(1/nu) / gamma(3/nu) )
          g = nu / ( lambda * (2^(1+1/nu)) * gamma(1/nu) )
          Density = g * exp (-0.5*(abs(x/lambda))^nu) / sd
          return(Density) }

      # Distribution Function:
        pged = function(q, mean = 0, sd = 1, nu = 2) {
          # q - Vector of quantiles
          q = (q - mean ) / sd
          lambda = sqrt ( 2^(-2/nu) * gamma(1/nu) / gamma(3/nu) )
          g = nu / ( lambda * (2^(1+1/nu)) * gamma(1/nu) )
          h = 2^(1/nu) * lambda * g * gamma(1/nu) / nu
          s = 0.5 * ( abs(q) / lambda )^nu
          Distribution = 0.5 + sign(q) * h * pgamma(s, 1/nu)
          return(Distribution) }

      # Quantile Function:
        pged = function(p, mean = 0, sd = 1, nu = 2) {
          # p - Vector of probabilities
          lambda = sqrt ( 2^(-2/nu) * gamma(1/nu) / gamma(3/nu) )
          g  = nu / ( lambda * (2^(1+1/nu)) * gamma(1/nu) )
          h = 2^(1/nu) * lambda * g * gamma(1/nu) / nu
          s = 0.5 * ( abs(p) / lambda )^nu
          Quantiles = qgamma(s, 1/nu)
          return(Quantiles) }

      # Random Deviates:
        rged = function(n, mean = 0, sd = 1, nu = 2) {
          # n - Number of random deviates to be generated
          r = rgamma(n, shape = 1/nu, scale = nu)
          Deviates = r^(1/nu) * sign(runif(n)-0.5)
          return(Deviates) }
      \end{verbatim}
 \end{quote}
\normalsize




% -----------------------------------------------------------------------------


\vspace{0.5cm}

\emph{Student-t Distribution:}

Bollerslev [1987], Hsieh [1989)], Baillie and Bollerslev [1989],
Bollerslev, Chou, and Kroner [1992], Palm [1996], Pagan [1996)],
and Palm and Vlaar [1997] among others showed that the Student-t
distribution better captures the observed kurtosis in empirical
log-return time series. The density $f^\star(z|\nu)$ of the
\emph{Standardized Student-t Distribution}\footnote{The
standardized Student-t probability function is selected by setting
\texttt{distribution="std".}} can be expressed as\footnote{Note,
when setting $\mu=0$ and $\sigma^2 = \nu/(\nu-2)$ formula
(\ref{student.distribution}) results in the usual one-parameter
expression for the Student-t distribution as implemented in the
\textsf{R} function $dt$.}


\begin{equation}\label{std.pdf}
    f^\star(z|\nu) ~=~
        \frac{\Gamma(\frac{\nu+1}{2})}
            {\sqrt{\pi(\nu-2)}\Gamma(\frac{\nu}{2})} ~
        \frac{1}{
            \left (
                1 + \frac{z^2}{\nu-2}
            \right )^{\frac{\nu+1}{2}} ~
            }
        ~ = ~ \frac{1}
            {\sqrt{\nu-2}\,\mathrm{B}\big(\frac{1}{2},\frac{\nu}{2}\big)}
        \frac{1}{
            \left (
                1 + \frac{z^2}{\nu-2}
            \right )^{\frac{\nu+1}{2}} ~
            }~,
\end{equation}


where $\nu > 2$ is the shape parameter and $\rm{B}\it{(a,b) =
}\rm{\Gamma}\it{(a)}\rm{\Gamma}\it{(b)/}\rm{\Gamma}\it{(a+b)}$ the
Beta function. Again, arbitrary location and scale parameters
$\mu$ and $\sigma$ can be introduced via the transformation $ z
\rightarrow \frac{z-\mu}{\sigma}$. Odd central moments of the
standardized Student-t distribution are zero and those of even
order can be computed from


\begin{equation}\label{std.moments}
    \mu_{2r} = \sigma^{2r} \mu^\star_{2r} ~=~
        \sigma^{2r} ~ (\nu -2)^\frac{r}{2} ~
        \frac
            {\mathrm{B}(\frac{r+1}{2},\frac{\nu-r}{2})}
            {\mathrm{B}(\frac{1}{2},\frac{\nu}{2})}  ~.
\end{equation}


Skewness $\gamma_1$ and kurtosis $\gamma_2$ are given by


\begin{equation}\label{std.central.moments}
    \gamma_1 = \frac{\mu_3}{\mu_2^{3/2}} = 0 ~, ~~~~
    \gamma_2 = \frac{\mu_4}{\mu_2^2} - 3 = ? ~.
\end{equation}


%
%
%*********************************************************************
\begin{figure}
\hspace{1cm}
\includegraphics[width=14cm]{figures/Figure2.pdf}
%\caption
\footnotesize{
\vspace{0.5cm}
\\ $\blacksquare$
Figure 2: The figure shows on top the density and distribution for
the Student-t distribution with unit variance for three different
degrees of freedom, $\nu = 2.5, 5, 10$. The graph for the largest
value of $\nu$ is almost undistinguishable from a normal
distribution. The lower left shows a histogram of 1000 random
deviates distributed for $\nu = 2.5$. The thick line fits the
theoretical density and the thin line corresponds to a normal
distribution with the same variance. The last graph shows the
kurtosis as function of the number of degrees of freedom. The
kurtosis diverges for $\nu \rightarrow 2$ and its asymptotic
values for $\nu \rightarrow \infty$ approaches zero, the value for
the normal distribution.}
\end{figure}
%*********************************************************************
%
%

\vspace{0.5cm}

\footnotesize
 \textbf{Function: Student-t Distribution - }
 \texttt{[dpqr]std}
 \begin{quote}
      In this example we show how to write a function to compute
      density, distribution function, quantile function and how to
      generate random deviates for the Student-t distribution
      with mean equal to \texttt{mean}, standard deviation equal
      to \texttt{sd}, and shape parameter equal to \texttt{nu}.

      \emph{Hint:} To Compute the distribution function make use
      of the relationship to the (non-standardized) Student-t
      distribution function which is part of \textsf{R}'s base
      package.

      \begin{verbatim}
      # Density Function:
        dstd = function(x, mean = 0, sd = 1, nu = 5) {
          # x - Vector of quantiles
          s = sqrt(nu/(nu-2))
          z = (x-mean) / sd
          Density = dt(x = z*s, df = nu) * sd / s)
          return(Density) }

      # Distribution Function:
        pstd = function (q, mean = 0, sd = 1, nu = 5) {
          # q - Vector of quantiles
          s = sqrt(nu/(nu-2))
          z = (q-mean) / sd
          Distribution = pt(q = z*s, df = nu)
          return(Distribution) }

      # Quantile Function:
        qstd = function (p, mean = 0, sd = 1, nu = 5) {
          # p - vector of probabilities
          s = sqrt(nu/(nu-2))
          Quantiles = qt(p = p, df = nu) * sd / s + mean
          return(Quantiles) }

      # Random Deviates:
        rstd = function(n, mean = 0, sd = 1, nu = 5) {
          # n - Number of random deviates to be generated
          s = sqrt(nu/(nu-2))
          Deviates = rt(n = n, df = nu) * sd / s + mean
          return(Deviates) }
      \end{verbatim}
 \end{quote}
\normalsize


% -----------------------------------------------------------------------------


\vspace{0.5cm}
%\newpage

\emph{Standardized Skewed Distributions:}

Fernandez and Steel [1998] proposed a quite general approach that
allows the introduction of skewness in any continuous unimodal and
symmetric distribution by changing the scale at each side of the
mode

\begin{equation}\label{skewed.distribution}
    f(z | \xi) ~=~
        \frac{2}{\xi + \frac{1}{\xi} }
        \left [
            f (\xi z) H(-z)  ~ + ~ f (\frac{z}{\xi}) H(z)
        \right ] ~,
\end{equation}

where $0< \xi < \infty$ is a shape parameter which describes the
degree of asymmetry. $\xi=1$ yields the symmetric distribution
with $f(z|\xi=1) = f(z)$. $H(z)=(1+\mathrm{sign}(z))/2$ is the
Heaviside unit step function. Mean $\mu_\xi$ and variance
$\sigma_\xi$ of $f(z|\xi)$ depend on $\xi$ and are given by


\begin{eqnarray}\label{skewed.moments}
    \mu_\xi & = & M_1 \big( \xi - \frac{1}{\xi} \big)
    \nonumber
    \\
    \sigma^2_\xi & = & (M_2-M_1^2) \big( \xi^2 + \frac{1}{\xi^2} \big)
    + 2 M_1^2 - M_2
    \nonumber
    \\
    M_r & = & 2 \int_0^\infty x^r ~ f(x) ~ dx ~,
\end{eqnarray}

where $M_r$ is the $r$-th absolute moment of $f(x)$ on the
positive real line. Note, that $M_2\equiv 1$ if $f(x)$ is a
standardized distributions.

\vspace{0.5cm}

\footnotesize
 \textbf{Function: Compute Absolute Moments - }
 \texttt{xmpGarchDISTmoments}
 \begin{quote}
      In this example we show how to write a function which
      computes the absolute moments $M_r$ for the standardized
      normal, GED and Student-t distributions or any other
      standardized distribution.

      \begin{verbatim}
      absMoments =
      function(n, density, ...) {

        # "density" is a character string giving the name of a
        #    standardized distribution, e.g. dnorm, dged, dstd, ...
        # "..." are additional arguments passed to the
        #    standardized distribution, e.g. nu for dged and dstd.

        # norm - Normal Distribution:
        if (density == "dnorm") {
           return (sqrt(2)^n * gamma((n+1)/2) / sqrt(pi)) }

        # ged - Generalized Error Distribution:
        if (density == "ged") {
           parm = function(n, nu) {
             lambda = sqrt ( 2^(-2/nu) * gamma(1/nu) / gamma(3/nu) )
             return ((2^(1/nu)*lambda)^n * gamma((n+1)/nu) / gamma(1/nu)) }
           return(parm(n, ...)) }

        # std - Student-t Distribution:
        # Note: nu > 2*n
        if (density == "std") {
           parm = function(n, nu) {
             return (beta(1/2+2*n, nu/2-2*n)/beta(1/2, nu/2) * sqrt(nu-2)) }
           return(parm(n, ...)) }

        # Any other standardized Distribution will be numerically integrated ...
        fun = match.fun(density)
        moments = function(x, n, ...) { x^n * fun(x, ...) }
        M = absMoments.error <<-NULL
        for (i in n) {
            I = integrate(moments, 0, Inf, n=i, ...)
            M = c(M, 2*I$value)
            absMoments.error <<- c(absMoments.error, 2*I$abs.error) }
        return(M)
      }

      # Example - Try GED:
      > absMoments(1:5, density = "dged", nu = 1)
      [1]  0.7071068  1.0000000  2.1213203  6.0000000 21.2132034

      # Example - Try Standardized Laplace Distribution:
      # We expect the same results ...
      > dlaplace = function(x) { exp(-sqrt(2)*abs(x)) / sqrt(2) }
      > absMoments(1:5, density = "dlaplace")
      [1]  0.7071068  1.0000000  2.1213203  6.0000000 21.2132034
      > absMoments.error
      [1] 1.7577e-07  2.728e-06  1.550e-05  3.867e-05  2.365e-06
      \end{verbatim}
\end{quote}
\normalsize


Now we introduce a re-parametrization in such a way that the
skewed distribution becomes standardized with zero mean and unit
variance\footnote{Lambert and Laurent (2001) have also
reparametrized the density of Fernandez and Steel (1998) as a
function of the conditional mean and of the conditional variance
in such a way that again the innovation process has zero mean and
unit variance.}. We call a skewed distribution function with zero
mean and unit variance \emph{Standardized Skewed Distribution}
function.


The probability function $f^\star(z|\xi)$ of a standardized skewed
distribution can be expressed in a compact form as

\begin{eqnarray}\label{skewed.distribution}
    f(z | \xi \theta) & = &
        \frac {2 \sigma} { \xi + \frac{1}{\xi} } ~
        f^\star ( z_{ \mu_\xi \sigma_\mu \xi } | \theta)
    \nonumber
    \\
    z_{ \mu_\xi \sigma_\mu \xi } & = &
        \xi^{ \rm{sign} ( \sigma_\xi\, \it{z} + \mu_\xi ) }
        ( \sigma_\xi z + \mu_\xi\ ) ~,
\end{eqnarray}

where $f^\star(x|\theta)$ may be any standardized symmetric
unimodal distribution function, like the Standardized Normal
distribution (\ref{normal.distribution}), the Standardized
Generalized Error distribution (\ref{ged.distribution}) or the
Standardized Student-t distribution (\ref{student.distribution}).
$\mu_\xi$ and $\sigma_\xi$ can be calculated via equation
(\ref{skewed.moments}).

Transforming $z \rightarrow \frac {z - \mu} {\sigma}$ yields
skewed distributions, where the parameters have the following
interpretation:

\begin{quote}
 \begin{itemize}
    \item $\mu$ is the mean or location parameter,
    \item $\sigma$ is the standard deviation or the
        dispersion parameters,
    \item $0 < \xi < \infty$ a shape parameter that
        models the skewness\footnote{Setting $\xi=1$
        yields the symmetric distribution}.
    \item $\theta$ an optional set of shape parameters
        that model higher moments of even order like
        $\nu$ in the GED and Student-t distributions.
 \end{itemize}
\end{quote}


\vspace{0.5cm}

\footnotesize
 \textbf{Exercise: Standardized Skewed Distributions}
 \begin{quote}
      In this example we show how to write a function to compute
      density, distribution function, quantile function and how to
      generate random deviates for the standardized Student-t distribution
      with zero mean and unit variance, and shape parameter equal to \texttt{nu}.

      \begin{verbatim}
      # Density Function:
        .dsstd = function(x, nu, xi) {
          # Standardize:
          m1 = 2 * sqrt(nu-2) / (nu-1) / beta(1/2, nu/2)
          mu = m1*(xi-1/xi)
          sigma =  sqrt((1-m1^2)*(xi^2+1/xi^2) + 2*m1^2 - 1)
          z = x*sigma + mu
          # Compute:
          Xi = xi^sign(z)
          g = 2 / (xi + 1/xi)
          Density = g * dstd(x = z/Xi, nu = nu) * sigma
          return(Density) }

      # Distribution Function:
        .psstd = function(q, nu, xi) {
          # Standardize:
          m1 = 2 * sqrt(nu-2) / (nu-1) / beta(1/2, nu/2)
          mu = m1*(xi-1/xi)
          sigma =  sqrt((1-m1^2)*(xi^2+1/xi^2) + 2*m1^2 - 1)
          z = q*sigma + mu
          # Compute:
          Xi = xi^sign(z)
          g = 2 / (xi + 1/xi)
          Distribution = H(z) - sign(z) * g * Xi * pstd(q = -abs(z)/Xi, nu = nu)
          return(Distribution) }

      # Quantile Function:
        .qsstd = function(p, nu, xi) {
          # Standardize:
          m1 = 2 * sqrt(nu-2) / (nu-1) / beta(1/2, nu/2)
          mu = m1*(xi-1/xi)
          sigma =  sqrt((1-m1^2)*(xi^2+1/xi^2) + 2*m1^2 - 1)
          # Compute:
          g = 2  / (xi + 1/xi)
          sig = sign(p-1/2)
          Xi = xi^sig
          p = (H(p-1/2)-sig*p) / (g*Xi)
          Quantiles = (-sig*qstd(p=p, sd=Xi, nu=nu) - mu ) / sigma
          return(Quantiles) }

      # Random Deviates:
        .rsstd = function(n, nu, xi) {
          # Generate Random Deviates:
          weight = xi / (xi + 1/xi)
          z = runif(n, -weight, 1-weight)
          Xi = xi^sign(z)
          Random = -abs(rstd(n, nu=nu))/Xi * sign(z)
          # Scale:
          m1 = 2 * sqrt(nu-2) / (nu-1) / beta(1/2, nu/2)
          mu = m1*(xi-1/xi)
          sigma =  sqrt((1-m1^2)*(xi^2+1/xi^2) + 2*m1^2 - 1)
          Deviates = (Random - mu ) / sigma
          return(Deviates) }
      \end{verbatim}

      For the skewed normal and skewed generalized error
      distribution we have only to change the function names and
      to exchange the expression for the first absolute moment
      \texttt{m1} with the appropriate value. To generate
      skewed distributions with arbitrary mean and standard
      deviation, we have only to add a shift and scale
      transformation, e.g.

      \begin{verbatim}
      # Density Function:
      dsstd = function (x, mean = 0, sd = 1, nu = 5, xi = 1.5) {
        .dsstd(x = (x - mean)/sd, nu = nu, xi = xi)/sd }
      \end{verbatim}

      For details of the implementation inspect the functions:

      \begin{verbatim}
      [dpqr]snorm(x, mean, sd, xi)
      [dpqr]sged(x, mean, sd, nu, xi)
      [dpqr]sstd(x, mean, sd, nu, xi)
      \end{verbatim}

\end{quote}
\normalsize

%
%
%*********************************************************************
\begin{figure}[h]
\hspace{1cm}
\includegraphics[width=14cm]{figures/x.pdf}
%\caption
\footnotesize{
\\ $\blacksquare$
Figure 3: The figure shows on top the density and distribution for
the GED. Three cases are considered: The leptokurtic Laplace
distribution with $\nu=1$, the Normal distribution with $\nu=2$,
and the almost uniform distribution for large $\nu=10$. On the
lower left the ratio of two succeeding absolute moments is
displayed. For the Laplace distribution we get a straight line,
for distributions with thinner tails than the Laplace
distribution, the curve bends upwards, and for distributions with
thicker tails the curve bends downwards. On the lower right the
4th moment as a function of the shape parameter $\nu$ is shown.
Since the distribution is standardized, the fourth moment
coincides with the value of the kurtosis. Note, to obtain the
excess kurtosis we have to subtract $3$. For $\nu \rightarrow 0$
the kurtosis diverges and for $\nu \rightarrow \infty$ the
kurtosis tends to one. The circles mark the values for the Laplace
and Normal distributions.}
\end{figure}
%*********************************************************************
%
%


\vspace{0.5cm}
%\newpage

\emph{Distributional Parameter Fits:}

If the distribution of $z_i$'s is $F(z|\theta)$ and $\theta$ is an
unknown vector of distributional parameters, then we say that the
distribution is parametric. In such a setting the \emph{method of
maximum likelihood} is the appropriate technique for the
estimation and inference on $\theta$. For a continuous
distribution $F(z|\theta)$ the density will be written as
$f(z|\theta)$ and the joint density of a random sample $\{z_i\}$
is $\Pi_{i=1}^N ~ f(z_i | \theta)$. The likelihood of the sample
is this joint density evaluated at the observed sample values,
viewed as a function of $\theta$. The log-likelihood function
$\mathcal{L}_N(\theta)$ is its natural logarithm

\begin{equation}\label{log.likelihood}
    \mathcal{L}_N(\theta) ~ = ~
        \sum_{i=1}^N ~ \ln f(z_i | \theta) ~.
\end{equation}

%Define the \emph{information matrix} $H$ and the \emph{outer
%product matrix} $P$ by

%\begin{eqnarray}\label{matrix}
%    H & = &
%        - E \frac{\partial^2}{\partial\theta\partial\theta'}
%        \ln f(z_i | \theta_0) ~,
%    \\
%    P & = &
%        E \left (
%            \frac{\partial}{\partial\theta} \ln f(z_i | \theta_0)
%            \frac{\partial}{\partial\theta} \ln f(z_i | \theta_0)'
%        \right ) ~,
%\end{eqnarray}

%then two important features of the likelihood are the information
%matrix equality and the Cramer-Rao lower bound for
%estimation\footnote{However, the restriction to unbiased
%estimators means that the theorem has little direct relevance for
%finite sample estimation, Hansen 2003.} if $\widehat{\theta}$ is
%an unbiased estimator of $\theta \in \mathbb{R}$

%\begin{eqnarray}\label{relationships}
%    \frac{\partial}{\partial\theta} E \ln f(x_i | \theta)
%    |_{\theta=\theta_0} & = & 0 ~,
%    \\
%    Var(\widehat{\theta}) & \geq & \frac{1}{nV}
%\end{eqnarray}


The \emph{maximum likelihood estimator} or \emph{MLE}, named
$\widehat{\theta}$, are the values of the parameter set which
maximizes the likelihood or equivalently, which maximizes the
log-likelihood


% \underset{}{}

\begin{equation}\label{max.likelihood.estimator}
    \widehat{\theta} ~ = ~
        \underset{\theta}{\textrm{argmax}} ~ \mathcal{L}_N(\theta)
        ~.
\end{equation}


\footnotesize
 \textbf{Function: MLE Density Parameter Estimation - }
 \texttt{dFit}
 \begin{quote}
   In this example we show how to write a function which
   returns a S4 object of "nlmFit" with the estimated
   parameters of an arbitrary probability function via the
   maximum log-likelihood approach.

   \begin{verbatim}
      setClass("nlmFit", representation(
        call = "call", estimate = "numeric", fit = "list",
        title = "character", description = "character") )

      dFit =
      function(x, density, parm)
      {
        # "x" is a numeric vector of random deviates
        # "density" is a character string giving the name of the
        #    probability function whose parameters should be estimated
        # "parm" is a vector of valued parameters passed to the
        #    probability function with an initial guess for the optimizer.

        # Internal MLE Function:
        d = match.fun(density)
        if (length(parm) == 1)
            d.mle = function(x, y = x) { -sum(log(d(x=y, x[1]))) }
        if (length(parm) == 2)
            d.mle = function(x, y = x) { -sum(log(d(x=y, x[1], x[2]))) }
        if (length(parm) == 3)
            d.mle = function(x, y = x) { -sum(log(d(x=y, x[1], x[2], x[3]))) }
        if (length(parm) == 4)
            d.mle = function(x, y = x) { -sum(log(d(x=y, x[1], x[2], x[3], x[4]))) }

        # Estimate:
        fit = nlm(f = dsnorm.mle, p = parm, hessian = TRUE, print.level = 0, y = x)

        # Add names Attribute:
        names(fit$estimate) = names(fit$gradient) = c("mean", "  sd", "  xi")

        # Return Value:
        return(new("nlmFit",
            call = as.call(match.call()), estimate = fit$estimate, fit = fit,
            title = as.character(paste(density, "Fit")),
            description = as.character("MLE Parameter Estimation")))
      }
   \end{verbatim}

   Note, that the function \texttt{dFit} implemented in the
   \texttt{finGARCH} package also optionally allows to trace
   the iteration path of the optimization process and to plot
   the results. For the print method we refer to the source
   code.

   In the following example we show how to fit a simulated GED sample:

   \begin{verbatim}
      z = rsged(n = 1000, mean = 1, sd = 0.5, nu = 2.5, xi = 1.25)
      dFit(z, density = "dsged", parm = c(mean(z), sqrt(var(z), 2, 1))
   \end{verbatim}
 \end{quote}
\normalsize


\vspace{0.5cm}


\textsf{The Presample Specification:}

Because the mean equation and the variance equation is recursive
in nature, they require \emph{presample data} to initiate the
simulation.

For automatically generated presample data the presample is
created as a three column matrix of length \texttt{max(m,n,p,q)}.
The three columns have the time ordering $t_{1-L}, \dots,
t_{1-\ell}, \dots, t_0$, where $1 \leq \ell \leq L$ counts the
rows, and have the following meaning:

\footnotesize
\begin{quote}
    \textbf{The Default Presample Matrix}
    \vspace{0.25cm}
\begin{itemize}
    \item \emph{Column 1:}
        holds the pre-innovations $z_t$. The pre-innovations
        are random deviates generated from the distribution
        as specified in the specification structure.
    \item \emph{Column 2:}
        holds the pre-sigmas $\sigma_t$. All pre-sigmas are
        set to the expectation value of the conditional
        variance.
    \item \emph{Column 3:}
        holds the pre-series $x_t$. All pre-series values
        are set to the expectation value of the mean.
\end{itemize}
\end{quote}
\normalsize

To minimize transient effects, we recommend to specify the
\texttt{presample} long enough. For a given value of $L >
max(m,n,p,q)$ the iteration of the ARMA/GARCH process starts at
time $t_{-L+\max(m,n,p,q)}$ and the pre-sigmas and pre-series
values ar overwritten by the iterated time series values.
Alternatively, the \texttt{presample} can be fully specified by
the user.

\vspace{0.5cm}

\footnotesize
 \textbf{Example: GARCH Presample Generation}
 \texttt{ }
 \begin{quote}
      The following lines of code show how the presample is
      generated
      \begin{verbatim}
      ...
      \end{verbatim}
\end{quote}
\normalsize


The next example shows how to specify a presample for a typical
model from the ARMA-GARCH family.


\vspace{0.5cm}

\footnotesize
 \textbf{Example: GARCH Specification  - }
 \texttt{xmpGarchSpecification:}
 \begin{quote}
      Use the function \texttt{garchSpec()} to specify models
      from the ARMA-GARCH/APARCH family:
      \begin{verbatim}

      # 1. Specify an AR(1)-GARCH(1,1) with default presample
        seed(4711)
        model = list(ar=1, omega=1e-6, alpha=0.1, beta=0.3)
        spec = garchSpec(model=model)
        print(spec)

      # 2. AR(1)-GARCH(1,1) with default presample of length 10:
        seed(4711)
        model = list(ar=1, omega=1e-6, alpha=0.1, beta=0.3)
        spec = garchSpec(model=model, presample=10)
        print(spec)

      # 3. AR(1)-GARCH(1,1) with user defined presample:
        seed(4711)
        model = list(ar=1, omega=1e-6, alpha=0.1, beta=0.3)
        presamle.innovations = dnorm(10)
        sigma = sqrt(model$omega/(1-model$alpha-model$beta))
        presample.sigmas = rep(sigma, times=10)
        presample.series = rep(0, times=10)
        spec = garchSpec(model=model, presample=presample)
        print(spec)
      \end{verbatim}
 \end{quote}
\normalsize

\vspace{0.5cm}

The third example generates the following presample,

\footnotesize
 \textbf{Presample for an AR(1)-GARCH(1,1) Model}
 \begin{quote}
      \begin{verbatim}
      ...
      \end{verbatim}
\end{quote}
\normalsize

it is the same as the default presample from the second example.



\newpage

\subsection{Simulation of Time Series}

The \textsc{R}-function \texttt{garchSim(n, spec)} creates with
the information provided by the \emph{specification structure} an
artificial ARMA-GARCH time series. The function requires only two
arguments, the length of the time series to be simulated and the
specification structure. The function \texttt{garchSim} returns
the sample path for the simulated return series, for the
innovations, and for the conditional standard deviations.


\vspace{0.5cm}

\footnotesize
 \textbf{Function: GARCH Time Series Simulation - }
 \texttt{garchSim}\\
 \begin{quote}
   This function simulates an artificial ARMA time series with
   GARCH/APARCH errors.
   \begin{verbatim}
   garchSim = function(n, spec)
   \end{verbatim}
   \vspace{-0.5cm}
   \begin{itemize}
        \item \texttt{n} -  the length of the time series to be
            simulated,
        \item \texttt{spec} - the model specification, a S4 object
            of class \texttt{"garchSpec"} as returned from the
            the function \texttt{garchSpec}. Only the
            \texttt{garchSpec@model} slot is required to simulate
            the artificial GARCH process, the remaining arguments
            are optional and have default values.
    \end{itemize}
 \end{quote}
\normalsize

The following example shows how to use the function
\texttt{garchSim} and how to simulate some typical GARCH Models.

\vspace{0.5cm}

\footnotesize
 \textbf{Example: GARCH Simulation  - }
 \texttt{xmpGarchSimulation}
 \begin{quote}
      Use the function \texttt{garchSpec} to specify models from
      the ARMA-GARCH family:

  \begin{verbatim}
   # Specify ARCH(2):
     model <- list(omega=1e-6, alpha=c(0.1, 0.3), h0=1e-7)
     spec = garchSpec(model)
     x <- garchSim(model)
     plot(x, type="l", main="ARCH(2) Model")

   # Specify GARCH(1,1):
     model <- list(omega=1e-6, alpha=0.1, beta=0.8, h0=1e-7)
     x <- garchSim(model)
     plot(x, type="l", main="GARCH(1,1) Model")
 \end{verbatim}

 \end{quote}
\normalsize


%
%
%*********************************************************************
\begin{figure}[h]
\hspace{1cm}
\includegraphics[width=14cm, height=8cm]{figures/benchmark1.pdf}
%\caption
\footnotesize{
\\ $\blacksquare$
The figure shows ... .}
\end{figure}
%*********************************************************************
%
%


% -----------------------------------------------------------------------------
%\vspace{0.5cm}


\newpage

\subsection{Parameter Estimation}

Given a model for the conditional mean and variance and an
observed univariate return series, we use the maximum likelihood,
estimation approach to fit the parameters for the specified model
of the return series. The procedure infers the process innovations
or residuals by inverse filtering. Note, that this filtering
transforms the observed process $\varepsilon_t$ into an
uncorrelated white noise process $z_t$. The log-likelihood
function then uses the inferred innovations $z_t$ to infer the
corresponding conditional variances ${\sigma_t}^t$ via recursive
substitution into the model-dependent conditional variance
equations. Finally, the procedure uses the inferred innovations
and conditional variances to evaluate the appropriate
log-likelihood objective function. The procedure is implemented in
the function \texttt{garchFit()}.


\vspace{0.5cm}

\textsf{Maximum Likelihood Estimator:}

As already mentioned, the GARCH models are estimated using a
maximum likelihood estimation, MLE, approach. The MLE concept
interprets the density as a function of the parameter set,
conditional on a set of sample outcomes. The Normal distribution
is the standard distribution when estimating and forecasting GARCH
models. Using $\varepsilon = z_t \sigma_t$ the log-likelihood
function of the normal distribution is given by

\begin{eqnarray}
    \mathcal{L}_N(\theta) & = &
    \sum_{t=1}^T
        [ log( d(\varepsilon \sigma_t^{-1} - log \sigma_t ]
    \\
        & = & - \frac{1}{2} \sum_{t=1}^T [ log(2\pi) +
        log(\sigma_t^2) + z_t^2 ]
\end{eqnarray}

where $T$ is the number of observations.


\vspace{0.5cm}

\textsf{Parameter Constraints:}

If we use a solver for unconstrained numerical optimization to
maximize the log-likelihood function with respect to the vector of
parameters $\theta$, the inspected range of the parameter space is
unlimited. However, the problem is that $\omega > 0$ and $\delta$
have to be constrained in a semifinite interval, that $\alpha$ and
$beta$  have to be constrained in a finite interval $[0,1)$, and
$\gamma$ in $(-1,1)$. To impose constraints on a finite interval
one can easy perform the transformation

\begin{equation}
    \theta^\star \leftarrow
        u + \frac{v - u}{ 1 + e^{-\theta} }
\end{equation}

which relates monotonously the finite interval $[u,v]$ to the
infinite one. So, applying unconstrained optimization of the
log-likelihood function with respect to $\theta$ is equivalent to
applying constrained optimization with respect to $\theta^\star$.


\vspace{0.5cm}

\textsf{Optimization Algorithm:}

The function \texttt{garchFit} uses the \textsf{R} solver
\texttt{nlm}. This optimizer uses a Newton-type algorithm, Dennis
and Schnabel [1983], Schnabel, Koontz and Weiss [1985]. If the
function to be optimized has an attribute called \texttt{gradient}
or both \texttt{gradient} and \texttt{hessian}
attributes\footnote{Analytical expressions for the gradient and
hessian are not yet implemented.}, these will be used in the
calculation of updated parameter values, otherwise, numerical
derivatives are used. The optimizer returns the following
components:

\vspace{0.5cm}

\footnotesize
 \textbf{Function: Return Values of the Optimizer - }
 \texttt{nlm}
 \begin{quote}
  \begin{itemize}
    \item \texttt{minimum} - the value of the estimated
        minimum.
    \item \texttt{estimate} - the point at which the minimum
        value is obtained.
    \item \texttt{gradient} - the gradient at the estimated
        minimum.
    \item \texttt{hessian} - the hessian at the estimated
        minimum.
    \item \texttt{code} - the termination status of the
        optimization process
    \begin{itemize}
        \item \texttt{1} - the relative gradient is close to zero,
            current iterate is probably the solution.
        \item \texttt{2} - successive iterates within tolerance,
            current iterate is probably solution.
        \item \texttt{3} - last global step failed to locate a point
            lower than the estimate ``estimate''.  Either ``estimate''
            is an approximate local minimum of the function or the
            step tolerance ``steptol' is too small.
        \item \texttt{4} - the iteration limit was exceeded.
        \item \texttt{5} - the maximum step size ``stepmax'' exceeded
            five consecutive times. Either the function is unbounded
            below, becomes asymptotic to a finite value from above
            in some direction or ``stepmax'' is too small.
    \end{itemize}
    \item \texttt{iterations} - the number of iterations performed.
  \end{itemize}
 \end{quote}
\normalsize

The result of the optimization is added to the specification
structure and globally accessible.


\vspace{0.5cm}

\textsf{Initial Parameter Estimates:}

The optimizer requires a vector of initial parameter estimates for
the ARMA coefficients $a_i$ and $b_j$, for the GARCH/APARCH
coefficients $\omega$, $\alpha_i$, $\gamma_i$, and $\beta_j$, and
additionally for the mean $\mu$ and exponent $\delta$. If the
parameters for the distribution function should also be estimated,
these parameters have also to be initialized. By default all
parameters are automatically initialized by the function
\texttt{garchFit}. On the other hand all parameters can be
initialized by the user, thus the control of the initialization
remains with the user.

\vspace{0.5cm}

\footnotesize
 \textbf{Example: GARCH Parameter Estimation - }
 \texttt{xmpGarchSpecification}
 \begin{quote}
      Use the function \texttt{garchSpec()} to specify models from
      the ARMA-GARCH family:
      \begin{verbatim}
      # Specify ARCH(2):
        model <- list(omega=1e-6, alpha=c(0.1, 0.3), h0=1e-7)
        x <- garchSim(model)
        plot(x, type="l", main="ARCH(2) Model")

      # Specify GARCH(1,1):
        model <- list(omega=1e-6, alpha=0.1, beta=0.8, h0=1e-7)
        x <- garchSim(model)
        plot(x, type="l", main="GARCH(1,1) Model")
      \end{verbatim}
\end{quote}
\normalsize


\vspace{0.5cm}

\textsf{Putting All Together:}


\vspace{0.5cm}

\subsection{Diagnostic Analysis}

The \textsc{R}-functions \texttt{print}, \texttt{plot},
\texttt{summary} and \texttt{print.summary} are methods to print
and plot the results of the parameter estimation and to create a
report summarizing the results of a diagnostic analysis.

\vspace{0.5cm}

\textsf{Print and Plot the Results from the Fit:}

The \texttt{print} function takes as input a S4 object of class
\texttt{"garchFit"} which is the result of a GARCH maximum
log-likelihood estimation. The report lists following aspects of
the fit:

...

In the same way the \texttt{plot} function takes also as input a
S4 object of class \texttt{"garchFit"} and displays the following
graphs:

...

\vspace{0.5cm}

\textsf{Estimation Statistics:}

Q(20), $Q^2(20)$, P(50) AIC, Log-Lik


\vspace{0.5cm}

\textsf{Forecast Performance:}

% peters01a.pdf

\footnotesize
\begin{quote}
\begin{itemize}
    \item Mean Squared Errors (MSE)
    \item Median Squared Error (MedSE)
    \item Mean Absolute Error (MAE)
    \item Adjusted Mean Absolute Percentage Error (AMAPE)
    \item Theil Inequality Coefficient (TIC)
    \item Mincer-Zarnowitz R2 (R2)
\end{itemize}
\end{quote}
\normalsize

The first three criteria are well-known and self-explanatory. The
AMAPE is

the TIC is

and the R2 statistic from this regression therefore provides the
proportion of variances explained by the forecast (i.e., the
higher the R2 , the better the forecasts).


\vspace{0.5cm}

\textsf{Diagnostic Analysis:}


% MATLAB - Postprocessing:
% http://www.mathworks.com/access/helpdesk/help/toolbox/garch/garch.shtml

The postprocessing investigates the residuals $z_t$, and the
conditional standard deviations $\sigma_t$.

If you plot the ACF of the squared standardized innovations, they
also show no correlation: acf(innovations/sigmas)2). Now compare
the ACF of the squared standardized innovations in this figure to
the ACF of the squared returns prior to fitting the default model.
The comparison shows that the default model sufficiently explains
the heteroscedasticity in the raw returns.

3. Quantify and Compare Correlation of the Standardized
Innovations. Compare the results below of the Q-test and the ARCH
test with the results of these same tests in the preestimation
analysis. In the preestimation analysis, both the Q-test and the
ARCH test indicate rejection (H = 1 with pValue = 0) of their
respective null hypotheses, showing significant evidence in
support of GARCH effects. In the postestimate analysis, using
standardized innovations based on the estimated model, these same
tests indicate acceptance (H = 0 with highly significant pValues)
of their respective null hypotheses and confirm the explanatory
power of the default model.

% MATLAB - End of Postprocessing

\vspace{0.5cm}

\footnotesize
 \textbf{Example: GARCH Specification  - }
 \texttt{xmpGarchSpecification:}
 \begin{quote}
      Use the function \texttt{garchSpec()} to specify models from
      the ARMA-GARCH family:

      \begin{verbatim}
      # Specify ARCH(2):
        model = list(omega=1e-6, alpha=c(0.1, 0.3), h0=1e-7)
        spec = garchSpec()
        x <- garchSim(model)
        plot(x, type="l", main="ARCH(2) Model")

      # Specify GARCH(1,1):
        model = list(omega=1e-6, alpha=0.1, beta=0.8, h0=1e-7)
        spec = garchSpec()
        x <- garchSim(n = 1000, spec)
        plot(x, type="l", main="GARCH(1,1) Model")

      # Specify AR(1)-APARCH(1,1):
        model = list(omega=1e-6, alpha=0.1, beta=0.8, h0=1e-7)
        spec = garchSpec()
        x <- garchSim(n = 1000, spec)
        plot(x, type="l", main="AR(1)-APARCH(1,1) Model")
      \end{verbatim}
\end{quote}
\normalsize


% -----------------------------------------------------------------------------


\vspace{0.5cm}

\subsection{Forecasting}

One of the major aspects in the investigation of heteroskedastic
time series is to produce forecasts. Function for forecasts of
both the conditional mean and the conditional variance are
available as well as for several forecast error measures.

\vspace{0.5cm}

\textsf{Forecasting the Conditional Mean:}

The optimal $h$-step-ahead predictor of $x_{t+h}$ given the
information up to time $t$ is

\begin{equation}\label{mean.forecast}
    \widehat{\sigma}_{t+h|t}^2 ~=~
\end{equation}

\vspace{0.5cm}

\textsf{Forecasting the Conditional Variance:}

The conditional variance can be forecasted independently from the
conditional mean.

For a GARCH(p,q) process, the optimal $h$-step-ahead forecast of
the conditional variance $\widehat{\omega}_{t+h|t}^2$ is computed
recursively from

\begin{equation}\label{garch.forecast}
    \widehat{\sigma}_{t+h|t}^2 ~=~ \widehat{\omega}
       ~+~ \sum_{i=1}^q \widehat{\alpha}_i \varepsilon_{t+h-i|t}^2
       ~+~ \sum_{j=1}^p \widehat{\beta}_j \sigma_{t+h-j|t}^2 ~,
\end{equation}

where $\varepsilon_{t+i|t}^2 = \sigma_{t+i|t}^2$ for $i > 0$ while
$\varepsilon_{t+i|t}^2 = \varepsilon_{t+i}^2$ and
$\sigma_{t+i|t}^2 = \sigma_{t+i}^2$ for $i \leq 0$.

For a APARCH(p,q) process the distributional of the innovations
may have an effect on the forecast, the optimal $h$-step-ahead
forecast of the conditional variance $\widehat{\omega}_{t+h|t}^2$
is computed recursively from

\begin{eqnarray}\label{aparch.forecast}
    \widehat{\sigma}_{t+h|t}^\delta & = &
        E ( \sigma_{t+h}^\delta | \Omega_t )
    \\
    & = &
        \widehat{\omega} +
        \sum_{i=1}^q \widehat{\alpha}_i
        E [ (
            | \varepsilon_{t+h-i} | - \widehat{\gamma}_i \varepsilon_{t+h-i}
            )^{\widehat{\delta}} | \Omega_t
          ] +
        \sum_{j=1}^p \widehat{\beta}_j \sigma_{t+h-j|t}^{\widehat{\delta}}
\end{eqnarray}

where ...


\vspace{0.5cm}

\footnotesize
 \textbf{Example: GARCH Forecast  - }
 \texttt{xmpGarchSpecification:}
 \begin{quote}
      Use the function \texttt{garchSpec()} to specify models from
      the ARMA-GARCH family:
      \begin{verbatim}
      # Specify ARCH(2):
        model <- list(omega=1e-6, alpha=c(0.1, 0.3), h0=1e-7)
        x <- garchSim(model)
        plot(x, type="l", main="ARCH(2) Model")

      # Specify GARCH(1,1):
        model <- list(omega=1e-6, alpha=0.1, beta=0.8, h0=1e-7)
        x <- garchSim(model)
        plot(x, type="l", main="GARCH(1,1) Model")
      \end{verbatim}
\end{quote}
\normalsize


\vspace{0.5cm}

\textsf{Forecast Error Measures:}

% -----------------------------------------------------------------------------


\newpage


\section{Numerical Investigations}

\vspace{0.5cm}

When analyzing and forecasting GARCH models we have to implement
the algorithms. Through the complexity of the GARCH models it is
evident that different software implementations have different
functionalities, drawbacks and features and may lead to
differences in the numerical results. McCullough and Renfro
[1999], Brooks, Burke and Persand [2001], and Laurent and Peters
[2003] compared the results of several software packages. These
investigations demonstrate that there could be major differences
between estimated GARCH parameters from different software
packages. Therefore we use the benchmark suggested by Fiorentini,
Calzolari, and Panattoni [1996] to test our \textsl{R}-package.

% Matlab Documentation:
% http://www.mathworks.com/access/helpdesk/help/toolbox/garch/garch.shtml


\vspace{0.5cm}

\subsection{GARCH(1,1) Benchmark}

We use as \emph{the benchmark} the GARCH(1,1) model estimated with
the
software\footnote{$http://qed.econ.queensu.ca/jae/1996-v11.4/fiorentini-calzolari-panattoni/$
\htmladdnormallink{\textsc{SOFTWARE}}{http://qed.econ.queensu.ca/jae/1996-v11.4/fiorentini-calzolari-panattoni/}}
as implemented by Fiorentini, Calzolari, and Panattoni [1996]
using analytical derivatives. For the time series data we take the
DEM/GBP daily exchange
rates\footnote{$ftp://www.amstat.org\/JBES_View/96-2-APR/bollerslev_ghysels/bollerslev.sec41.dat.$
\htmladdnormallink{\textsc{DATA}}{ftp://www.amstat.org\/JBES_View/96-2-APR/bollerslev_ghysels/bollerslev.sec41.dat}}
as published by Bollerslev and Ghysels [1996]. The series contains
a total of 1975 daily observations sampled during the period from
January 2, 1984, to December 31, 1991. This benchmark was also
used by McCullough and Renfro [1999], and by Brooks, Burke, and
Persand [2001] in their analysis of several GARCH software
packages.


\vspace{0.5cm}

\subsection{Modelling DEM/GBP Rates}

Figure 4.1 shows some stylized facts of the log-returns of the
daily DEM/GBP FX rates. The distribution is leptokurtic and skewed
to negative values. The log-returns have a mean value of $\mu =
-0.00016$ of almost zero, a skewness of $\varsigma = -0.25$, and
an excess kurtosis of $\kappa = 3.62$. The histogram of the
density and the quantile-quantile plot graphically display this
behavior. Furthermore, the autocorrelation function of the
absolute values of the returns, which measure volatility, decay
slowly.

\vspace{0.5cm}

\footnotesize
 \textbf{Example: GARCH(1,1)  - Stylized Facts}
 \texttt{xmpGarchDEMGBP:}
 \begin{quote}
      \begin{verbatim}
      # Load Data Set:
        data(dem2gbp)
        demgbp = dem2gbp[, 1]/100
      # Plot Log-Return Series:
        ts.plot(demgbp, xlab = "index", ylab = "log Return", col = "steelblue3")
        title(main = "DEM/GBP FX Rate")
      # Histogram Plot:
        hist(demgbp, n= 20, col = "steelblue", probability = TRUE,
          border = "white", xlim = c(-0.02, 0.02) )
        x = seq(-0.02, 0.02, length = 201)
        lines(x, dnorm(x = x, mean = mean(demgbp), sd = sqrt(var(demgbp))))

      # Quantile - Quantile Plot:
        qqnorm(demgbp, xlab = "Normal Quantiles", ylab = "Empirical Quantiles",
          col = "steelblue3")
        qqline(demgbp)
      # Partial Autocorrelation:
        acf(abs(demgbp))
      \end{verbatim}
\end{quote}
\normalsize

%
%
%*********************************************************************
\begin{figure}
\hspace{1cm}
\includegraphics[width=14cm]{figures/xmpGarchDEMGBP.pdf}
%\caption
\footnotesize{
\\ $\blacksquare$
The figure shows the returns, their distribution, the
quantile-quantile plot, and the autocorrelation function of the
volatility.}
\end{figure}
%*********************************************************************
%
%

We use the default GARCH(1,1) model to fit the parameters of the
time series and compare later the results with the benchmark.

\vspace{0.5cm}

\footnotesize
 \textbf{Example: GARCH(1,1) Benchmark  - }
 \texttt{xxx:}
 \begin{quote}
      \begin{verbatim}
      # Get the Data:
        data(demgpb)
      # Specify the Model:
        spec = garchSpec()
      # Estimate the Parameters:
        fit = garchFit(x, spec)
        print(fit)
      # Diagnostic Analysis:
        summary(fit)
      # Predict one Step Ahead:
        predict(fit)
      \end{verbatim}
\end{quote}
\normalsize

The result are the following:


\vspace{0.5cm}

\subsection{Benchmark Comparison}

Brooks, Burke, and Persand [2001] used the GARCH benchmark to
compare the accuracy of GARCH(1,1) model estimations among several
econometric software packages. The results of the default
estimation of the GARCH(1,1) model in each package is shown in
figure XX.




%
%
%*********************************************************************
\begin{figure}[h]
\hspace{1cm}
\includegraphics[width=14cm]{figures/benchmark1.pdf}
%\caption
\footnotesize{
\\ $\blacksquare$
The figure shows ... .}
\end{figure}
%*********************************************************************
%
%


%
%
%*********************************************************************
\begin{figure}[t]
\hspace{1cm}
\includegraphics[width=14cm]{figures/benchmark2.pdf}
%\caption
\footnotesize{
\\ $\blacksquare$
The figure shows ... .}
\end{figure}
%*********************************************************************
%
%

\vspace{0.5cm}

We have added to the table the results as obtained from our
\texttt{finGARCH} package, from the SPlus software package and
from the GARCH Ox software package. In addition we have
reinvestigated the FX rates with the GARCH toolbox from
\textsc{matlab}.

Also listed is the benchmark result obtained  by Fiorentini,
Calzolari, and Panattoni [1996].


% ---------------------------------------------------------------------------

\newpage
.
\newpage

\section{Summary and Next Steps}

\vspace{0.5cm}

This is the first approach to an \emph{educational} software
implementation of the GARCH modelling process. Much value was put
to show how to use the \textsf{S} language and how to implement
functions to the \textsf{R} environment.

The aim was to implement the whole software in \textsf{R} without
using any partial implementations in Fortran, C, or C++. Although
this would speed up the execution time for the parameter
estimation essentially, we did not make use of this opportunity.
This keeps the software more transparent for everybody who is
interested in the code and applied algorithms and would learn
programming techniques under \textsf{R}.

The next steps we will follow are,

\begin{itemize}
    \item to implement analytical derivatives for the gradient
        vector and hessian matrix,
    \item to add long memory behavior in the mean equation,
        and
    \item to add further volatility models for the variance
        equation.
\end{itemize}

Analytical derivatives for GARCH model were derived by, for the
APARCH mode by , and for the FIGARCH model by . The long memory
behavior in the mean equation will be modelled by ... The
volatility models we like to include are ...

Everybody who likes to contribute to this package will be welcome.



% *****************************************************************************


\newpage


\section{GARCH Function Summary}

\vspace{0.5cm}

The GARCH functions are part of Rmetrics \texttt{fSeries} package
All functions are entirely written in \textsf{S}. So it becomes
very easy to inspect the code which is especially useful for
teaching financial engineers and for teaching computational
finance.

The \texttt{fSeries} package can be downloaded from the Rmetrics
website \emph{www.rmetrics.org}.


% *****************************************************************************

\vspace{0.5cm}

\subsection{List of R Functions}


The following summary gives an overview over the GARCH functions
available in the \texttt{fSeries} package. The functions can be
grouped according to their purpose in \emph{Distribution
Functions}, \emph{GARCH Modelling Functions}, and \emph{Utility
Functions}.


% -----------------------------------------------------------------------------


\vspace{0.25cm}

\textsf{Distribution Functions}


\footnotesize{
\begin{quote}
      The collection of distribution functions adds the Generalized
      Error Distribution and a re-parameter- ized Student-t
      Distribution to the library.
      Both distributions have parameterizations where the location
      parameter has the meaning of the mean, and the squared scale
      parameter has the meaning of the variance. Furthermore, a
      function is added which allows to create skewed
      distributions from any standardized probability function.
      In addition the collection includes a program which computes
      absolute moments for standardized distributions, and a
      function which fits the parameters of a density vie the
      max log likelihood estimation approach.

\end{quote}
\begin{verbatim}
      [dpqr]ged                Generalized Error Distribution
      [dpqr]std                Modified Student-t Duistribution
      [dpqr]skew               Skewed Distributions from a Standardized PDF
      absMoments               Compute absolute Moments
      nlmFit                   MLE Fit of distributional parameters
\end{verbatim}
}\normalsize


% -----------------------------------------------------------------------------


\vspace{0.25cm}

\textsf{ARMA-GARCH Modelling Functions}


\footnotesize{
\begin{quote}
      The collection of ARMA-GARCH modelling functions includes functions
      to simulate artificial GARCH/APARCH processes, to estimate the
      parameters for a specified model from empirical time series
      data, to perform a diagnostic analysis of the fit and to forecast one
      step ahead in time.

\end{quote}
\begin{verbatim}
      garchSpec                Specify an ARMA-GARCH/APARCH model
      garchFit                 Fit the GARCH parameters from empirical data
      garchDiag                Perform a diagnostic analysis
      garchPredict             Predict one step ahead
\end{verbatim}
}\normalsize


% -----------------------------------------------------------------------------


\vspace{0.25cm}

\textsf{Utility Functions}


\footnotesize{
\begin{quote}
      The collection of utility functions includes a function to
      compute the Heaviside unit step function and some related
      functions.
\end{quote}
\begin{verbatim}
      H                        Heaviside unit step function
      Sign                     Just another signum function
      boxcar                   The boxcar function
      ramp                     The ramp function
\end{verbatim}
}\normalsize



% -----------------------------------------------------------------------------


\vspace{0.5cm}

\subsection{List of Data Sets}

\footnotesize{
\begin{quote}
    The \texttt{fSeries} package includes for GARCH modelling three data
    sets used in examples and for benchmarks.

    \emph{DEM/GBP Exchange Rate Data:} A price and return series which'
    contains daily observations of the German Mark versus
    British Pound foreign exchange rates. The sample period is from
    January 2, 1984, to December 31,1991, for a total of 1975 daily
    observations of. The data can be downloaded from the JBES FTP
    site\footnote{$ftp://www.amstat.org\/JBES_View/96-2-APR/bollerslev_ghysels/bollerslev.sec41.dat.$}.

    \emph{NASDAQ Composite Index Data:} The series contains daily
    closing values of the NASDAQ Composite Index. The sample period
    is from January 2, 1990, to December 31, 2001, for a total of
    3028 daily equity index observations. The data can be downloaded
    from the Market Data section of the NASDAQ Web
    site\footnote{$http://www.marketdata.nasdaq.com/mr4b.html$}.

    \emph{NYSE Composite Index Data:} The series contains daily
    closing values of the New York Stock Exchange Composite Index.
    The sample period is from January 2, 1990, to December 31, 2001,
    for a total of 3028 daily equity index observations of the
    NYSE Composite Index. The data can be downloaded from the NYSE web
    site\footnote{$http://www.nyse.com/marketinfo/marketinfo.html$}.

    \emph{CAC40 French Index:} The series contains daily values for
    the CAC40 French Index ranging from January, 1995 up to December,
    1999, in total 1249 observations. The data were used in examples
    of the GARCH Ox package, Laurent and Peters [2002], and are part
    of their software
    distribution\footnote{$http://www.core.ucl.ac.be/~laurent/G@RCH/site/download.htm$}.
 \end{quote}
\begin{verbatim}
      demgbp.csv               DEM-GBP Foreign exchange rates
      cac40.csv                CAC-40 log-returns and volume data
      nasdaq                   NASDAQ Index
\end{verbatim}
}\normalsize


% -----------------------------------------------------------------------------


\vspace{0.5cm}

\subsection{List of Examples}

\footnotesize
\begin{quote}
      The \texttt{fSeries} package includes several example and
      demonstration files for GARCH modelling, which show how to use
      the functions:
\end{quote}
\begin{verbatim}
      xmpDist                       Distribution Examples
      xmpGarch                      Garch modelling examples
\end{verbatim}
\normalsize


% -----------------------------------------------------------------------------


\vspace{0.5cm}

\subsection{Software Licence}



% *****************************************************************************


\newpage
\pdfbookmark[1]{References}{Bibliography}

\begin{thebibliography}{99}

% http://www.mathworks.com/access/helpdesk/help/toolbox/garch/app_bibl.shtml

\bibitem{.}
    ... not yet complete

\bibitem{bera93a} % NA
    Bera, A.K., Higgins H.L., (1993);
    \emph{A Survey of ARCH Models: Properties, Estimation and Testing},
    Journal of Economic Surveys 7, 305--366.

\bibitem{bollerslev86a} % ok
    Bollerslev, T., (1986);
    \emph{Generalised Autoregressive Conditional Heteroskedasticity},
    Journal of Econometrics 31, 307--327.

\bibitem{bollerslev92} % ok
    Bollerslev T., Chou R.Y., Kroner K.F., (1992);
    \emph{ARCH Modelling in Finance: A Review of the Theory and
        Empirical Evidence};
    Journal of Econometrics 52(5), 5--59.

\bibitem{bollerslev88a}
    Bollerslev T., Engle R.F., NelsonD.B., (1994);
    \emph{ARCH Model},
    Chapter 49 of Handbook of Econometrics Volume IV,
        edited by Engle and McFadden),
    Elsevier Science, pp2961--3031.

\bibitem{bollerslev02a} % ok
    Bollerslev, T., Ghysels, E. (1996);
    \emph{Periodic Autoregressive Conditional Heteroscedasticity},
    Journal of Business and Economic Statistics 14, 139--151.

\bibitem{box73a}
    Box G.E.P., Tiao G.C., (1973);
    \emph{Bayesian Inference in Statistical Analysis},
    Addison-Wesley, Publishing Reading, MA.

\bibitem{brooks00b}
    Brooks R.D., Faff R.W., McKenzie M.D., Mitchell H., (2000);
    \emph{A Multi-Country Study of Power ARCH Models and
        National Stock Market Return},
    Journal of International Money and Finance 19, 377--397.
    \htmladdnormallink{\textsc{pdf}}
    {http://www.bf.rmit.edu.au/Ecofin/workingpapers/98-4.pdf}

\bibitem{brooks01a}
    Brooks C., Burke S.P., Persand G., (2001);
    \emph{Benchmarks and the Accuracy of GARCH Model Estimation},
    International Journal of Forecasting 17, 45-56.
    \htmladdnormallink{\textsc{LNK}}
    {http://www.itp.phys.ethz.ch/econophysics/R/publications/brooks01a.pdf}

\bibitem{dennis83a}
    Dennis J.E., Schnabel R.B., (1983);
    \emph{Numerical Methods for Unconstrained Optimization and Nonlinear
        Equations},
    Prentice-Hall, Englewood Cliffs, NJ.

\bibitem{ding93a} % OK
    Ding, Z., Granger C.W.J., Engle R.F. (1993);
    \emph{A Long Memory Property of Stock Market Returns and a New
        Model},
    Journal of Empirical Finance 1, 83--106.

\bibitem{engle86a}
    Engle, R.f. (1982);
    \emph{Autoregressive Conditional Heteroscedasticity
        with Estimates of the Variance of United Kingdom
        Inflation},
    Econometrica 50, 987--1007.

\bibitem{engle86a}
    Engle, R. F., Bollerslev T. (1986);
    \emph{Modelling the Persistence of Conditional Variances}
    Econometric Reviews 5, 1--50.

\bibitem{engle01a}
    Engle, R.F. (2001);
    \emph{GARCH 101: An Introduction to the Use of
        ARCH/GARCH models in Applied Econometrics},
    forthcoming Journal of Economic Perspectives.
    \htmladdnormallink{\textsc{pdf}}
    {http://marshallinside.usc.edu/simrohoroglu/teaching/543/spring2002/garch101.pdf}

\bibitem{engle02a}
    Engle, R. F., (2002);
    \emph{New Frontiers for ARCH Models}
    NYU Preprint, 29 pp.
    \htmladdnormallink{\textsc{pdf}}
    {http://www-sigproc.eng.cam.ac.uk/Research/ReadingGroup/material/Engle_Frontiers.pdf}

\bibitem{fiorentini96a}
    Fiorentini, G., Calzolari, G., Panattoni, L. (1996);
    \emph{Analytic derivatives and the computation of GARCH
        estimates},
    Journal of Applied Econometrics 11, 399--417.

\bibitem{geweke86a}
    Geweke, J. (1986);
    \emph{Modeling the Persistence of Conditional Variances:
    A Comment},
    Econometric Review 5, 57--61.

\bibitem{glosten93a}
    Glosten, L., Jagannathan R., Runkle D. (1993);
    \emph{On the Relation Between Expected Value and the
        Volatility of the Nominal Excess Return on Stocks},
    Journal of Finance 48, 1779--1801.

\bibitem{hansen94a}
    Hansen, B. (1994);
    \emph{Autoregressive Conditional Density Estimation},
    International Economic Review 35, 705--730.

    %http://www.econ.brown.edu/fac/Peter_Hansen/Papers/vola.pdf}

\bibitem{harvey81a}
    Harvey, A.C. (1981);
    \emph{The Econometric Analysis of Time Series},
    Oxford.

\bibitem{higgins92a}
    Higgins, M.L., Bera A.K. (1992);
    \emph{A Class of Nonlinear Arch Models International},
    Economic Review 33, 137--158.

\bibitem{lambert01a} % APARCH
    Lambert, P., Laurent S. (2000);
    \emph{Modelling Skewness Dynamics in Series of Financial Data},
    Discussion Paper, Institut de Statistique, Louvain-la-Neuve.
    \htmladdnormallink{\textsc{pdf}}
    {http://www.core.ucl.ac.be/~laurent/pdf/Lambert-Laurent.pdf}

\bibitem{lambert02a} % APARCH
    Lambert, P., Laurent S. (2001);
    \emph{Modelling Financial Time Series Using GARCH-Type
        Models and a Skewed Student Density},
     Mimeo, Universite de Liege.

\bibitem{laurent02a.pdf} % GARCH OX 3.2
    Laurent S., Lambert, P. (2002);
    \emph{A Tutorial for GARCH 2.3, a Complete Ox Package for
        Estimating and Forecasting ARCH Models},
    GARCH 2.3 Tutorial, 71 pp.
    \htmladdnormallink{\textsc{pdf}}
    {http://fmwww.bc.edu/ec-p/software/ox/Garch23_Tutorial.pdf}

\bibitem{laurent03a.pdf} % GARCH OX 3.2
    Laurent S. (2003);
    \emph{Analytical derivates of the APARCH model},
    Priprint, University of Namur, 8 pp.
    \htmladdnormallink{\textsc{pdf}}
    {http://www.core.ucl.ac.be/~laurent/pdf/CE.pdf}

\bibitem{ling02a}
    Ling, S., McAleer M. (2002);
    \emph{Stationarity and the Existence of Moments of a Family
        of GARCH processes},
    Journal of Econometrics 106, 109--117.

\bibitem{ling02a}
    Ling, S., McAleer M. (2002);
    \emph{Necessary and Sufficient Moment Conditions for the
        GARCH(r,s) and Asymmetric Power GARCH(r,s) Models},
        Econometric Theory 18, 722--729.

\bibitem{lombardi01a}
    Lombardi, M., Gallo G. (2001);
    \emph{Analytic Hessian Matrices and the Computation of FIGARCH
        Estimates},
    Manuscript, Universita degli studi di Firenze.
    \htmladdnormallink{\textsc{pdf}}
    {http://www.ds.unifi.it/ricerca/pubblicazioni/working_papers/2002/wp2002_03.pdf}
    %http://www.ds.unifi.it/~mjl/papers/Anhess.pdf

\bibitem{mccullough99a}
    McCullough, B.D., Renfro, C.G. (1999);
    \emph{Benchmarks and Software Standards: A Case Study of GARCH
        Procedures},
    Journal of Economic and Social Measurement 25, 59--71.
    \htmladdnormallink{\textsc{pdf}}
    {http://qed.econ.queensu.ca/faculty/mackinnon/econ872/papers/mccullough.pdf}

\bibitem{nelson91a} % ok
    Nelson, D.B., (1991);
    \emph{Conditional Heteroscedasticity in Asset Returns: A New
        Approach},
        Econometrica, 59, 347--370.

\bibitem{pentula86a}
    Pentula, S. (1986);
    \emph{Modeling the Persistence of Conditional Variances: A Comment},
    Econometric Review 5, 71--74.

\bibitem{peters01a}
    Peters J.P. (2001);
    \emph{Estimating and Forecasting Volatility of Stock Indices Using
        Asymmetric GARCH Models and (Skewed) Student-t Densities},
    Preprint, University of Liege, Belgium, 20 pp.
    \htmladdnormallink{\textsc{pdf}}
    {http://www.panagora.com/2001crowell/2001cp_50.pdf}

\bibitem{poon01}
    Poon, S.H. Granger C.W.J. (2001);
    \emph{Forecasting Financial Market Volatility: A Review},
    Manuscript, Department of Economics, UCSD.
    \htmladdnormallink{\textsc{pdf}}
    {http://www.eco.fundp.ac.be/cerefim/varpaper/200209.\%20(Granger\%20and\%20Poon)-Forecasting\%20Volatility\%20in\%20Financial\%20Markets\%20-\%20A\%20Review.pdf}

\bibitem{rabemananjara93a}
    Rabemananjara R., Zakoian J. M. (1993);
    \emph{Threshold Arch Models and Asymmetries in Volatility},
    Journal of Applied Econometrics 8, 31--49.

\bibitem{schnabel85a}
     Schnabel R.B., Koontz J.E., Weiss B.E., (1985);
     \emph{A Modular System of Algorithms for Unconstrained Minimization},
     ACM Trans. Mathematical Software 11, 419--440.

\bibitem{schwert90a}
    Schwert, W. (1990);
    \emph{Stock Volatility and the Crash of 87},
    Review of Financial Studies 3, 77--102.

\bibitem{taylor86a}
    Taylor, S. (1986);
    \emph{Modelling Financial Time Series},
    Wiley, New York.

\bibitem{zakoian94a}
    Zakoian, J.-M. (1994);
    \emph{Threshold Heteroskedasticity Models},
    Journal of Economic Dynamics and Control 15, 931--955.


\end{thebibliography}


% *****************************************************************************


\end{document}
